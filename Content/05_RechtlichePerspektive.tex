\section{Rechtliche Perspektive: Schutz geistiger Leistung und Daten im KI-Kontext}

Die rechtliche Bewertung von KI-generierten Inhalten ist für diese Arbeit vor allem dort relevant, wo sie in technische Anforderungen übersetzbar wird. Aus Sicht der Informatik sind Rechtstexte weniger \enquote{nur} Restriktionen, sondern beschreiben Randbedingungen für Systemdesign, Datenflüsse, Dokumentation und Verantwortlichkeiten. Dieses Kapitel skizziert daher die urheberrechtliche Grundlinie zur menschlichen Urheberschaft und Implikationen des AI Act für Transparenz und Governance\cite[vgl.][]{eu_ai_act_2024}.

\subsection{Urheberrechtliche Grundlinie: menschliche Urheberschaft und Nachweisbarkeit}
Das deutsche Urheberrecht schützt nach § 2 Abs. 2 UrhG \enquote{nur persönliche geistige Schöpfungen}. Der Urheber ist gemäß § 7 UrhG \enquote{der Schöpfer des Werkes}, also eine natürliche Person. Ein KI-System kann daher nicht selbst Urheber sein.

Für KI-gestützte Kreativität ist technisch vor allem die Konsequenz entscheidend: Urheberrechtlicher Schutz folgt nicht automatisch aus der Nutzung eines Tools, sondern hängt davon ab, ob ein individueller, gestaltender menschlicher Beitrag am konkreten Ergebnis nachvollziehbar ist (z.\,B. durch Auswahl-, Bearbeitungs- oder Kompositionsentscheidungen).

Ein prominentes Fallbeispiel ist das Bild \enquote{Théâtre D’opéra Spatial} von Jason Allen, bei dem das US Copyright Office Urheberrechtsschutz verneinte, weil es an hinreichender menschlicher Urheberschaft fehle\cite[vgl.][]{CopyrightGov}. Auch wenn die Rechtslage in den USA nicht unmittelbar auf Deutschland übertragbar ist, illustriert der Fall den allgemeinen Trend: Je autonomer ein System das Ergebnis prägt, desto schwieriger wird die Zuschreibung.

Für technische Kontexte folgt daraus ein pragmatischer Engineering-Punkt: Wenn Organisationen KI kreativ einsetzen, werden Prozessartefakte (Prompt-Versionen, Iterationen, Auswahlentscheidungen, Nachbearbeitungsschritte, Modellversion) zu wichtigen Nachweisen, um menschliche Beiträge plausibel zu dokumentieren.


\subsection{EU-KI-Verordnung (AI Act): Transparenz, Dokumentation und Governance}
Der AI Act ergänzt die Urheberrechtsfrage um einen risikobasierten Regulierungsrahmen für KI-Systeme. Für generative KI und General-Purpose AI Models (GPAI) sind insbesondere Pflichten relevant, die sich in technische Umsetzungsaufgaben übersetzen lassen\cite[vgl.][]{eu_ai_act_2024}.

Aus technischer Perspektive sind vier Umsetzungsfelder zentral:
\begin{enumerate}
	\item \textbf{Kennzeichnung und Herkunft:} Mechanismen, die KI-generierte Inhalte als solche erkennbar machen (z.\,B. UI-Hinweise, Metadaten, Watermarking-Ansätze) – besonders in Kontexten mit Täuschungs- oder Desinformationsrisiken.
	\item \textbf{Dokumentation und Nachweisfähigkeit:} Versionierung von Modellen, Datenpipelines und Evaluationsartefakten sowie technische Dokumentation (z.\,B. Model Cards/Datasheets) unterstützen die Nachvollziehbarkeit von Fähigkeiten, Grenzen und Updates.
	\item \textbf{Transparenz über Trainingsdaten:} Zusammenfassungen zur Art der Trainingsdaten und Datenquellen helfen Governance, Audits und die Bewertung von Risiken (z.\,B. Bias, Datenherkunft, urheberrechtliche Konflikte).
	\item \textbf{Betriebliches Risikomanagement:} Monitoring, Incident-Handling und klare Verantwortlichkeiten (Anbietende/Betreibende/Nutzende) werden Teil des Systems, nicht nur des \enquote{Drumherums}.
\end{enumerate}

Für die Autorschaftsdebatte bedeutet das weniger eine rechtliche \enquote{Neudefinition des Autors} als eine stärkere Verpflichtung zur Transparenz über maschinelle Anteile. Technisch gewinnen damit Provenienz- und Prozessinformationen an Bedeutung (z.\,B. Modellversion, Erzeugungsmodus, Bearbeitungsschritte), um Verantwortung und Integrität nachvollziehbar zu halten.

\subsection{Zwischenfazit: Recht als Design-Constraint}
Aus technischer Perspektive ergibt sich: Urheberrecht und AI Act adressieren unterschiedliche Schutzgüter (kreative Leistung, Systemrisiken), wirken aber gemeinsam als Rahmenbedingungen für KI-Systeme\cite[vgl.][]{eu_ai_act_2024}. Für die weitere Arbeit ist daher leitend, dass philosophische Konzepte (Autorschaft, Verantwortung) und technische Praxis (Datenpipeline, Logging, Retention, Kennzeichnung, Versionierung) zusammen gedacht werden müssen: Nur so werden menschliche Beiträge und Systemwirkungen überhaupt nachvollziehbar und bewertbar.

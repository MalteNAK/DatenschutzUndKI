\section{Technische Perspektive: Autorschaft in der algorithmischen Kreativität}

Aufbauend auf den philosophischen Grundlagen und der technischen Funktionsweise generativer KI untersucht dieses Kapitel, wie sich Autorschaft aus technischer Perspektive durch algorithmische Kreativität verändert. Im Fokus steht die Generierung durch KI-Systeme: Wie wird aus einem Prompt ein Output, welche Akteure und Komponenten wirken daran mit, und warum erschweren Intransparenzen (Black Boxes) sowie die Mensch-Maschine-Kooperation eine eindeutige Zuschreibung?

\subsection{Der kreative Prozess in KI-Systemen}

Die Generierung eines KI-basierten Werkes lässt sich vereinfacht als Dreischritt beschreiben: \textit{Prompt} → \textit{Modell} → \textit{Output}. Anders als bei klassischer Werkschöpfung sind dabei mehrere technische Komponenten beteiligt, die das Ergebnis mitprägen. Diese verteilte Generierung von Werken führt zu einer Form der Verantwortungsdiffusion, wie sie für algorithmische Systeme typisch ist: Entscheidungen und Effekte lassen sich nicht mehr eindeutig einzelnen Akteuren zuschreiben~\cite{Mittelstadt_EthicsOfAlgorithms_2016}.

\subsubsection{Von der Eingabe zur Ausgabe: Die technische Pipeline}

Der Prozess beginnt mit dem \textit{Prompt} als Eingabe durch einen menschlichen Nutzer. Er setzt den Rahmen für den zu generierenden Inhalt: bei Textgeneratoren oft als kurze Anweisung (\textit{z.\,B. \enquote{Schreibe ein Gedicht über den Winter}}), bei Bildgeneratoren häufig als detaillierte Beschreibung von Stil, Motiv und Atmosphäre.

Die Transformation erfolgt im \textit{Modell}, einem neuronalen Netzwerk mit vielen Parametern, die während des Trainings aus großen Datensätzen statistische Muster gelernt haben. Je nach Modelltyp (z.\,B. Transformer oder Diffusionsmodell) entsteht der Output schrittweise, etwa Wort für Wort oder durch Umwandlung von Rauschen in ein Bild.

Der \textit{Output} ist das generierte Werk (Text, Bild, Musik etc.). Dieser ist in der Regel nicht deterministisch: Selbst bei gleichen Prompts können unterschiedliche Ergebnisse entstehen, da viele Modelle auf Zufallselemente (Sampling) setzen~\cite{vaswani2023attentionneed}.


\subsubsection{Technische Urheberschaft: Daten, Algorithmen und Modelle als ``Mit-Autoren''}

Aus technischer Sicht wird die Urheberfrage komplex, weil mehrere Komponenten den Output beeinflussen. Mindestens vier Akteure bzw. Entitäten sind beteiligt:

\begin{enumerate}
    
    \item \textbf{Die Trainingsdaten:} Modelle lernen aus großen Datensätzen, die häufig auch urheberrechtlich geschützte Inhalte enthalten. Dadurch können Stil- und Strukturmerkmale als statistische Muster in die Generierung einfließen.
    
    \item \textbf{Die Entwickler:} Architektur, Trainingsverfahren und Sicherheitsmechanismen setzen den technischen Rahmen, innerhalb dessen generiert wird.
    
    \item \textbf{Das trainierte Modell:} Als ausführende Instanz transformiert es den Prompt in einen Output; es handelt dabei ohne Bewusstsein oder Intentionalität.
    
    \item \textbf{Der Nutzer:} Prompting, Auswahl und Iteration steuern Richtung und Qualität des Ergebnisses.
\end{enumerate}

Diese Vielschichtigkeit begünstigt eine \textit{verteilte Urheberschaft}: Das Werk entsteht als Ergebnis einer Kette technischer und menschlicher Entscheidungen, ohne klaren singulären Schöpfer.

\subsection{Transparenz und Nachvollziehbarkeit}

Ein zentrales Problem ist die mangelnde Transparenz vieler Modelle. Die Black-Box-Problematik meint hierbei, dass selbst Entwickler oft nicht erklären können, warum ein Modell genau diese Ausgabe erzeugt~\cite{Mittelstadt_EthicsOfAlgorithms_2016}.

Neuronale Netzwerke arbeiten mit Gewichtungen, die im Training angepasst werden. Der Parameterraum ist so komplex, dass interne Entscheidungswege kaum direkt interpretierbar sind. Welche Merkmale aus Trainingsdaten zu einer konkreten Ausgabe beigetragen haben, bleibt häufig unklar.

Das erschwert die Zuschreibung von Autorenschaft: Wenn der Entstehungsweg nicht nachvollziehbar ist, lassen sich Beiträge von Daten, Algorithmus und Prompt nur schwer abgrenzen. Ebenso wird die Bewertung heikel, etwa ob unzulässig nahe Reproduktionen entstehen oder ob die menschliche Steuerung als eigenständige Leistung gilt~\cite{Mittelstadt_EthicsOfAlgorithms_2016}~\cite{Coeckelbergh_AI_Ethics_2020}. \par
XAI-Ansätze versuchen, Modelle zumindest teilweise erklärbarer zu machen, etwa durch Visualisierungen, Attribution-Methoden oder vereinfachte Ersatzmodelle. Für Autorschaftsfragen können solche Methoden helfen, Einflussfaktoren besser abzuschätzen; sie liefern jedoch typischerweise nur Teilinformationen und bieten keine vollständige Nachvollziehbarkeit des Generierungsprozesses.

\subsubsection{Bedeutung für die Zuschreibung von Autorenschaft und die Mensch-Maschine-Kooperation}

Transparenz ist nicht nur technisch, sondern auch normativ relevant~\cite{Coeckelbergh_AI_Ethics_2020}. Ohne Nachvollziehbarkeit wird es schwierig, Begriffe wie Intentionalität oder Originalität sinnvoll auf KI-Outputs zu beziehen~\cite{Floridi_EthicsOfInformation_2013}. Zugleich wird die Idee eines klar identifizierbaren Autors fragiler: Die Werkgenese ist verteilt und oft intransparent. Das spricht für Autorschaftskonzepte, die mehrere Beiträge und Verantwortlichkeiten mitdenken.

Diese Unschärfe verstärkt sich in der Praxis durch die Mensch-Maschine-Kooperation. KI-Tools verschieben Rollen im kreativen Prozess: Statt alleiniger menschlicher Produktion entsteht eine \textit{Co-Creation}, in der Mensch und System gemeinsam zum Ergebnis beitragen. Der Mensch wird dabei häufig zum \textit{Kurator}, der Vorgaben formuliert, Varianten auswählt und iterativ verfeinert. Diese Tätigkeit erfordert kreative Kompetenzen (Prompts, Auswahl, Integration), unterscheidet sich aber von klassischer Produktion, weil Kontrolle und Ausgestaltung teilweise in das System verlagert werden.

Damit verändert sich auch das Verständnis von Kreativität. KI-Systeme haben kein Bewusstsein und arbeiten statistisch, erzeugen aber Outputs, die als kreativ oder sogar \enquote{originell} wahrgenommen werden. Kreativität lässt sich dadurch stärker als Eigenschaft von Prozess und Ergebnis verstehen, nicht nur als Ausdruck bewusster Intention. Gleichzeitig verschieben sich Anforderungen an kreative Berufe (z.B. Prompting, Verständnis von Modellgrenzen, kritische Integration), während Standardisierung und Homogenisierung drohen, wenn viele auf dieselben Modelle zurückgreifen~\cite{Coeckelbergh_AI_Ethics_2020}.
\subsection{Zwischenfazit: Technische Rekonzeption der Autorschaft}

Die technische Perspektive macht deutlich, dass KI-generierte Werke nicht das Ergebnis eines singulären schöpferischen Akts sind, sondern aus einem verteilten Zusammenspiel von Trainingsdaten, Entwicklerentscheidungen, Modellarchitektur und Nutzersteuerung hervorgehen. Diese Analyse erlaubt eine präzise Beschreibung der Werkgenese, liefert jedoch keine eigenständigen Kriterien dafür, wie Autorschaft normativ zu bewerten oder zuzuschreiben ist.

Die Black-Box-Problematik verschärft dies, weil Beiträge einzelner Komponenten schwer bewertbar sind. Ohne Transparenz bleibt unklar, wie \enquote{neu} ein Output ist und wie stark er Muster rekombiniert.

Zugleich verschiebt Co-Creation die menschliche Rolle vom alleinigen Schöpfer hin zum Kurator, der Prozesse steuert und Ergebnisse auswählt. Das verlangt eine Neubewertung dessen, was als kreative Leistung gilt.

Technisch betrachtet sind KI-generierte Werke das Resultat eines verteilten, oft intransparenten Prozesses, der klare Zuschreibungen erschwert. Damit legt die technische Analyse normative Anschlussfragen offen, die über die Beschreibung hinausgehen.

Diese Fragen betreffen vor allem Verantwortung, Fairness und den Umgang mit geistigen Vorleistungen. Sie lassen sich nicht aus der Funktionsweise der Systeme selbst beantworten, sondern erfordern eine ethische Reflexion, die im folgenden Kapitel vorgenommen wird.
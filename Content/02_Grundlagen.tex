\section{Grundlagen: Autorschaft und Künstliche Intelligenz}\label{Grundlagen}
\subsection{Historischer und philosophischer Begriff der Autorschaft}
Heutzutage, sowie seit der Neuzeit und insbesondere im Zuge der Aufklärung und der, im späten 18. Jahrhundert aufkommenden romantischen Genieästhetik, beherrscht die Rolle des Autors den Diskurs von fast jedem erdachten Werk \cite{Tod_des_Autors}. Im Folgenden soll das Autorschaftsverständnis untersucht werden, indem auf die Produktion eines kreativen Werks eingegangen wird. Zum Einen durch ein schöpferisches Individuum und zum Anderen durch die Kreation in kollektiver Form. Zudem werden die damit verbundenen Konzepte von Originalität, Inspiration und geistigem Eigentum behandelt. Damit schließlich diskutiert werden kann, wie KI die Autorschafts-Debatte erneut belebt wird.  
\subsubsection{Das schöpferische Individuum}
Künstliche Intelligenz stört die Diskussion rund um Autorschaft, indem die Fragen, wer ein Werk geschaffen hat und wie es geschaffen wurde, neu betrachtet werden müssen. Nach Immanuel Kants \citetitle{Kant_KritikDerUrteilskraft} entwickelt sich ein Verständnis von ästhetischer Autorschaft, welche untrennbar mit dem schöpferischen Individuum verbunden ist. 
Laut Kant setzt Ästhetische Autorschaft ein intentionales und verantwortbares Handeln voraus. Somit beginnt Autorschaft nicht nur wenn ein Werk entsteht, sondern dann wenn diesem Werk ein Ausdruck eines Subjekts verliehen werden kann. Ein zentrales Konzept, welches Kant in diesem Prozess beschreibt, ist das Genie. Es sei ein natürliches Talent \enquote{durch welches die Natur der Kunst die Regel gibt} \cite{Kant_KritikDerUrteilskraft}. Demnach wird dem Schöpfer eines Werks von Kant mehr vorrausgesetzt als bloße Regelanwendung oder Nachahmung, sondern eine originäre schöpferische Leistung. Kreative Produktion ist für Kant daher nicht vollständig rationalisierbar oder algorithmisierbar; sie entzieht sich der vollständigen Formalisierung. Ein Werk ist nicht bloß neu, sondern Ausdruck einer freien geistigen Tätigkeit.

Generative KI erfüllt diese Bedingungen prinzipiell nicht. Ihre Outputs beruhen auf der Optimierung formaler Zielgrößen innerhalb vorgegebener Architekturen. Weder setzt das System eigene Zwecke noch kann es Verantwortung für seine Hervorbringungen übernehmen. Selbst wenn KI funktional Neuheit erzeugt, bleibt diese Neuheit regelgebunden und fremdgesetzt.

Aus kantischer Perspektive scheitert KI damit nicht graduell, sondern kategorial an Autorschaft. Sie kann als Werkzeug in kreativen Prozessen fungieren, nicht jedoch als Träger ästhetischer Autorschaft im normativen Sinn.

\subsubsection{Kollektive Kreativität}
Während Kant Autorschaft stark an das Individuum bindet, problematisieren Michel Foucault und Roland Barthes diese Vorstellung grundlegend. Beide lösen die Idee des Autors als originäre Quelle von Bedeutung auf, wenn auch mit unterschiedlichen Akzenten.

Barthes argumentiert, dass ein Text nicht als Ausdruck innerer Intentionalität des Autors zu verstehen sei, sondern als „Gewebe aus Zitaten“ \cite{Tod_des_Autors}, das aus kulturellen, sprachlichen und historischen Bezügen besteht. Ferner bestätigt er dies wie folgt, \enquote{Ein Text ist aus vielfältigen Schriften zusammengesetzt, die verschiedenen Kulturen entstammen und miteinander in Dialog treten, sich parodieren, einander in Frage stellen. Es gibt aber einen Ort, an dem diese Vielfalt zusammentrifft, und dieser Ort ist nicht der Autor (wie man bislang gesagt hat), sondern der Leser. Der Leser ist der Raum, in dem sich alle Zitate, aus denen sich Schrift zusammensetzt, einschreiben, ohne dass ein einziges verloren ginge. Die Einheit eines Textes liegt nicht in seinem Ursprung, sondern in seinem Zielpunkt – wobei dieser Zielpunkt nicht mehr länger als eine Person verstanden werden kann. Der Leser ist ein Mensch ohne Geschichte, ohne Biographie, ohne Psychologie. Er ist nur der Jemand, der in einem einzigen Feld alle Spuren vereinigt, aus denen sich das Geschriebene zusammensetzt.}\cite{Tod_des_Autors}. Bedeutung entsteht demnach nicht im Akt des Schreibens, sondern im Lesen und im jeweiligen Kontext der Rezeption. Der Autor verliert seine privilegierte Stellung als Sinnstifter.

Foucault definiert den Autor, indem er ihn nicht als natürliche Person, sondern als Funktion des Diskurses beschreibt, die insbesondere dort relevant wird, wo Verantwortung, Eigentum und Kontrolle geregelt werden müssen \cite{Foucault_WasIstEinAutor_1969}. 

Die Autorfunktion erfüllt gesellschaftliche Aufgaben wie Zuschreibung, Verantwortungszuteilung, Kanonisierung und Kontrolle von Diskursen. Autorschaft entsteht dort, wo Zurechenbarkeit notwendig ist, nicht dort, wo kreative Produktion faktisch stattfindet. Außerdem definiert er diese Funktion als eine, "[…]die an das Rechts- und Staatssystem gebunden ist und die Gesamtheit der Diskurse einschließt, determiniert, ausdrückt;[…]" \cite{Foucault_WasIstEinAutor_1969}. Was die Rolle des Autors als eine veränderbare beschreibt, welche vom Rechts- und Staatssystem einzugrenzen ist.

Diese Perspektiven machen deutlich, dass kreative Werke stets in kollektiven Zusammenhängen entstehen: Sie greifen auf bestehende Diskurse zurück, reproduzieren kulturelle Muster und werden erst im sozialen Raum mit Bedeutung versehen. Kreativität ist somit nie rein individuell, sondern strukturell eingebettet und von geschichtlichen sowie äußerlichen Eindrücken geprägt.

Für KI bedeutet dies jedoch keine Aufwertung zur Autorschaft. Zwar operieren KI-Systeme kollektiv, beispielsweise kann man ihr Speisen aus großen Datenmengen kultureller Artefakte, mit der Recherche eines Autors vergleichen, jedoch fehlt ihnen der Selbstbezug, der für die Autorfunktion zentral ist. KI kann weder Verantwortung tragen noch als diskursives Subjekt auftreten. Autorschaft bleibt daher eine menschliche Zuschreibungspraxis, auch wenn die Produktion selbst zunehmend kollektiv und technisch vermittelt ist.

\subsubsection{Originalität, Inspiration und geistiges Eigentum}
Die Konzepte Originalität und Inspiration sind historisch eng mit dem Ideal des schöpferischen Individuums verbunden. Bei Kant ist Originalität ein zentrales Merkmal des Genies: Ein Werk gilt als originell, wenn es nicht bloß bestehende Regeln reproduziert, sondern neue hervorbringt. Inspiration ist dabei kein mystischer Akt, sondern Ausdruck freier schöpferischer Tätigkeit.

Im Kontext Künstlicher Intelligenz geraten diese Begriffe unter Druck. KI-Systeme erzeugen Inhalte, die neu erscheinen, ohne originär im kantischen Sinne zu sein. Ihre Leistungen basieren auf der Rekombination vorhandener Daten, nicht auf autonomer Regelsetzung. Originalität verschiebt sich dadurch von einem ontologischen, also einer Eigenschaft des \enquote{Seiendem}, zu einem funktionalen Kriterium: Neu ist, was als neu wahrgenommen wird.

Hier bietet der Utilitarismus von John Stuart Mill einen ergänzenden Zugang. Mill bewertet Handlungen nicht nach ihrer inneren Motivation, sondern nach ihren Folgen. Übertragen auf kreative Werke bedeutet dies, dass der moralische und rechtliche Status eines Outputs weniger von seiner Entstehung als von seinem gesellschaftlichen Nutzen abhängt. Ein Werk ist relevant, wenn es zur Förderung von Wissen, Wohlstand oder kultureller Entwicklung beiträgt.

Diese Perspektive ist besonders für Fragen des geistigen Eigentums relevant. Während Kant Autorschaft als Ausdruck personaler Freiheit begreift, erlaubt Mill eine stärker pragmatische Betrachtung: Schutzrechte können gerechtfertigt sein, wenn sie insgesamt positive Folgen haben, etwa durch Anreize für kreative Produktion. Im Fall von KI stellt sich daher weniger die Frage, ob sie originell „schafft“, sondern ob und wie ihre Nutzung reguliert werden sollte, um gesellschaftlichen Nutzen zu maximieren, ohne menschliche Urheberrechte zu untergraben.

Originalität, Inspiration und geistiges Eigentum erscheinen somit nicht als feste Eigenschaften eines Werkes, sondern als normative Zuschreibungen, die im Spannungsfeld zwischen individueller Autorschaft, kollektiver Kreativität und gesellschaftlichem Nutzen neu ausgehandelt werden müssen.

\subsection{Kreativität ohne Autorschaft}\label{KreativitätOhneAutorschaft}
Die bisherigen Überlegungen haben gezeigt, dass Autorschaft historisch eng an Intentionalität,
Verantwortung und subjektive Zuschreibung gebunden ist. Im Kontext generativer KI stellt sich jedoch
zunehmend die Frage, ob kreative Leistungen auch ohne Autorschaft im klassischen Sinne möglich
sind. Dieses Kapitel führt daher einen begrifflichen Unterschied zwischen Kreativität und
Autorschaft ein und untersucht, inwiefern maschinelle Systeme Neuheit erzeugen können, ohne als
Autoren gelten zu können.
\subsubsection{Funktionale Kreativität und Neuheit}

Boden und Edmonds unterscheiden verschiedene Formen von Kreativität, darunter kombinatorische,
explorative und transformatorische Kreativität \cite{Boden_MindsAndMachines_2009}. Kombinatorische
Kreativität bezeichnet die Erzeugung neuer Kombinationen aus bestehenden Elementen, während
explorative Kreativität innerhalb eines gegebenen Regelraums neue Möglichkeiten erschließt.
Transformatorische Kreativität hingegen setzt eine Veränderung der zugrunde liegenden Regeln
selbst voraus.

Generative KI-Systeme lassen sich überwiegend der kombinatorischen Kreativität zuordnen. Sie
erzeugen neuartige Outputs, indem sie statistisch gelernte Muster aus Trainingsdaten rekombinieren,
variieren und kontextabhängig fortsetzen. Die dabei entstehende Neuheit ist funktional: Ein Output
gilt als kreativ, sofern er für Rezipientinnen und Rezipienten neu, überraschend oder sinnvoll
erscheint.

Dieses Verständnis verschiebt den Kreativitätsbegriff von einer subjektgebundenen Eigenschaft hin
zu einem ergebnis- und prozessorientierten Kriterium. Neuheit wird nicht mehr aus einer
intentionalen schöpferischen Handlung abgeleitet, sondern aus der beobachtbaren Differenz zu
bestehenden Artefakten. Kreativität erscheint damit als Eigenschaft von Systemen oder Verfahren,
nicht notwendigerweise als Ausdruck eines schöpferischen Subjekts.

\subsubsection{Grenzen kreativer Zuschreibung ohne Intentionalität}
Auch wenn generative KI funktionale Kreativität realisieren kann, stößt die Zuschreibung von
Autorschaft an grundlegende Grenzen. Autorschaft impliziert nicht nur die Hervorbringung eines
Werkes, sondern auch die Fähigkeit zur Selbstzuschreibung, zur Rechtfertigung und zur
Übernahme von Verantwortung. Diese Dimensionen setzen Intentionalität und Selbstbezug voraus.

Maschinelle Systeme verfolgen keine eigenen Zwecke und verfügen über kein Verständnis ihrer
Ergebnisse. Ihre Outputs sind das Resultat formaler Optimierungsprozesse, nicht Ausdruck eines
reflektierten Gestaltungswillens. Selbst dort, wo KI-Ergebnisse als originell oder kreativ
wahrgenommen werden, fehlt damit die Grundlage für eine normative Zuschreibung von
Autorschaft.

Die Unterscheidung zwischen Kreativität und Autorschaft ist daher zentral für die weitere Analyse.
Kreative Leistung allein genügt nicht, um Autorschaft zu begründen. Vielmehr bleibt Autorschaft
eine menschliche Zuschreibungspraxis, die an Verantwortung, Zurechenbarkeit und normative
Einbettung gebunden ist. KI kann kreativ erscheinen, ohne Autor zu sein.

\subsection{Autorschaft als Zuschreibungs- und Ordnungskategorie}\label{AutorschaftAlsZuschreibung}
Wenn Kreativität auch ohne Autorschaft im klassischen Sinne möglich ist, stellt sich die Frage,
welche Funktion der Autorschaft im Kontext generativer KI weiterhin zukommt. Dieses Kapitel
versteht Autorschaft daher nicht primär als Beschreibung eines schöpferischen Ursprungs,
sondern als gesellschaftliche Zuschreibungs- und Ordnungskategorie, die Verantwortung,
Kontrolle und Sinnstiftung in komplexen Produktions- und Informationsprozessen strukturiert.

\subsubsection{Autorschaft zwischen Verantwortung, Kontrolle und Sinnzuschreibung}
Unabhängig von individuellen schöpferischen Leistungen erfüllt Autorschaft in modernen
Gesellschaften zentrale Ordnungsfunktionen. Sie dient der Zuschreibung von Verantwortung,
der Regulierung von Eigentum sowie der Sinn- und Bedeutungsstiftung kultureller Artefakte.
In diesem Sinne ist Autorschaft weniger eine Beschreibung faktischer Produktionsprozesse
als eine normative Kategorie gesellschaftlicher Ordnung.

Besonders in Kontexten, in denen Kontrolle, Haftung oder Anerkennung relevant sind, gewinnt
Autorschaft ihre regulative Bedeutung. Sie strukturiert Diskurse, ermöglicht Zuschreibung
und fungiert als Schnittstelle zwischen Werk, Produzent und Rezeption. Diese funktionale
Dimension wird im Kontext generativer KI besonders sichtbar, da technische Systeme zwar
Output erzeugen, jedoch keine Verantwortung übernehmen können.

\subsubsection{Autorschaft im informationsethischen Kontext}
Aus informationsethischer Perspektive lässt sich Autorschaft weniger als Besitzanspruch denn
als Verantwortung innerhalb eines Informationsökosystems verstehen~\cite{Floridi_EthicsOfInformation_2013}.
Kreative Werke erscheinen hier nicht als isolierte Produkte, sondern als Knotenpunkte in
Netzen aus Datenflüssen, Bedeutungszuschreibungen und Machtverhältnissen.

Generative KI verschärft diese Perspektive, da Trainingsdaten, Modellarchitekturen und
Nutzungskontexte eng miteinander verschränkt sind. Autorschaft fungiert in diesem Rahmen
als normative Orientierungskategorie, die Transparenz, Nachvollziehbarkeit und faire
Beteiligung einfordert.

Entscheidend ist dabei nicht, ob KI selbst als Autor gelten kann, sondern wie
Informationspraktiken so gestaltet werden, dass epistemische Integrität gewahrt bleibt.
Autorschaft wird damit zu einer Frage der Governance: Wer entscheidet über Daten,
Modelle und Einsatzkontexte, und wer trägt Verantwortung für die daraus entstehenden
Folgen?

\subsection{Funktionsweise generativer KI}
Generative KI bezeichnet Systeme, die auf Basis erlernter statistischer Muster neue Inhalte erzeugen können, etwa Texte, Bilder oder Audioinhalte~\cite{goodfellow2016_deepLearning}. Für Large Language Models (LLMs) besteht diese Generativität im Kern darin, aus einem gegebenen Kontext Wahrscheinlichkeitsverteilungen über mögliche Fortsetzungen zu berechnen und daraus Token-sequenzen zu generieren. Token sind dabei die vom Modell verwendeten Texteinheiten (z.B. Wortteile). Der „Output“ ist damit nicht das Ergebnis eines Verständnisses im strengen Sinne, sondern einer modellierten sprachlichen Regularität, die aus Trainingssätzen abstrahiert wurde.\par

\subsubsection{Prinzipien von Machine Learning und Large Language Models}
Machine Learning (ML) bezeichnet Verfahren, bei denen ein Modell aus Beispieldaten eine Abbildungsfunktion lernt, ohne dass alle Regeln explizit programmiert werden~\cite{bishop2006pattern}. Beim überwachten Lernen werden Eingaben und Zielausgaben (Labels) vorgegeben; beim unüberwachten Lernen werden Strukturen (z.\,B. Cluster) in Daten identifiziert; bei bestärkendem Lernen (Reinforcement Learning) werden Strategien über Rückmeldesignale optimiert. LLMs werden primär selbstüberwacht trainiert, indem sie aus Textsequenzen die Vorhersage des nächsten Tokens lernen~\cite{goodfellow2016_deepLearning}.\par

Moderne LLMs beruhen typischerweise auf der Transformer-Architektur. Zentrale Bausteine sind Tokenisierung (Zerlegung von Text in modellierbare Einheiten), Einbettungen (Embeddings) als Vektorrepräsentationen sowie das Attention-Prinzip, das es dem Modell erlaubt, relevante Kontextteile bei der Vorhersage zu gewichten~\cite{vaswani2023attentionneed}. Training und Inferenz unterscheiden sich dabei deutlich: Während im Training Parameter durch Optimierung (Gradientenabstieg und Backpropagation) angepasst werden, werden in der Anwendung (Inferenz) aus den fixierten Parametern Wahrscheinlichkeiten berechnet und per Decoding-Strategie (z.\,B. greedy, beam search, sampling) konkrete Ausgaben erzeugt~\cite{goodfellow2016_deepLearning}. Decoding-Strategien sind dabei Auswahlregeln wie aus Wahrscheinlichkeiten konkrete Token ausgewählt werden.\par

Viele Systeme werden zusätzlich anwendungsnah angepasst, etwa durch Fine-Tuning auf domänenspezifischen Daten oder durch Verfahren wie RLHF (Reinforcement Learning from Human Feedback), bei denen menschliche Präferenzen genutzt werden, um Ausgabequalität und Sicherheitsverhalten zu steuern~\cite{ouyang2022training}. Auch werden durch RLHF Modelle so angepasst, dass näher an menschlichen Präferenzen, wie Hilfsbereitschaft oder Regelkonformität, sind. Diese Schritte verändern jedoch nicht den Grundmechanismus: die wahrscheinlichkeitsbasierte Tokenfortsetzung auf Basis erlernter Regularitäten.\par
\subsubsection{Trainingsdaten, neuronale Netze und Mustererkennung}
Die Leistungsfähigkeit generativer Modelle hängt stark von Umfang, Vielfalt und Qualität der Trainingsdaten ab. Trainingskorpora bestehen typischerweise aus großen Mengen öffentlich zugänglicher Texte. In der Praxis werden häufig Bücher, wissenschftliche Texte und Code gemischt, je nach Zielsetzung des Modells. Aus ihnen lernt das Modell statistische Zusammenhänge auf verschiedenen Ebenen: Orthographie und Grammatik, semantische Assoziationen, Stilmerkmale sowie konventionalisierte Argumentations- und Textmuster.\par

Neuronale Netze implementieren diese Lernprozesse als Schichtung vieler parametrischer Operationen. Während der Trainingsphase werden Parameter so angepasst, dass die Vorhersagefehler über viele Beispiele minimiert werden. Dadurch entsteht eine Form der Mustererkennung, die nicht auf expliziten Regeln basiert, sondern auf „verteilten“ Repräsentationen~\cite{goodfellow2016_deepLearning}: Bedeutung wird nicht als feste Symbolstruktur kodiert, sondern als relationales Muster im Parameterraum.\par

Gleichzeitig erklärt dieser Mechanismus typische Eigenschaften generativer KI: Sie kann sehr kohärente Texte in bekannten Genres erzeugen, weil entsprechende Regularitäten in den Daten häufig vorkommen; sie kann aber auch plausibel klingende, dennoch falsche Aussagen erzeugen. Dieses Phänomen nennt sich Halluzination und entsteht, wenn das Modell statistisch plausible, aber faktisch inkorrekte Inhalte generiert. Der Output ist somit nicht per se verlässlich, sondern spiegelt statistische Plausibilität wider.\par

\subsubsection{Grenzen maschineller Kreativität: Reproduktion statt Intentionalität}
Im Anschluss an die zuvor diskutierten Autorschaftskonzepte lässt sich eine zentrale Grenze generativer KI so fassen: Ihre „Kreativität“ ist im Wesentlichen funktional und nicht intentional. Das Modell verfolgt keine eigenen Zwecke, hat kein Selbstverständnis und keine Verantwortungsfähigkeit; es optimiert lediglich eine formale Zielgröße (Vorhersagegüte bzw. Präferenzmodelle) und generiert daraus Ausgaben. Neuheit entsteht dabei häufig als Rekombination und Variation bestehender Muster, nicht als Ausdruck einer erfahrungsbasierten Perspektive oder eines reflektierten Gestaltungswillens~\cite{Boden_MindsAndMachines_2009}.\par

Diese Differenz zeigt sich besonders deutlich in Kontexten, in denen Autorschaft mit Zurechenbarkeit verknüpft ist: Während menschliche Autoren Gründe angeben, Absichten vertreten und Verantwortung übernehmen können, kann ein Modell dies nur sprachlich simulieren, indem es Muster von Begründungen reproduziert. Auch wenn LLM-Ausgaben für Rezipienten originell wirken können, folgt daraus weder ein innerer Sinneshorizont noch ein normativ zurechenbares Handeln.\par

Für die weitere Arbeit ist daher leitend: Generative KI kann produktiv an kreativen Prozessen beteiligt sein und neue Kombinationen im Ergebnis hervorbringen; sie bleibt jedoch ein Werkzeug, dessen Output aus statistischer Musterfortsetzung hervorgeht. Die Autorschaftsfrage verschiebt sich damit von der Idee eines „schöpferischen Subjekts“ hin zu Praktiken der Nutzung, Steuerung und Verantwortung in menschlich-technischen Konstellationen. Damit wird Autorschaft im KI-Kontext weniger zur Frage eines schöpferischen Innenlebens als zur Frage der Zurechnung: Wer setzt Ziele, steuert den Prozess und trägt Verantwortung für den Output?\par